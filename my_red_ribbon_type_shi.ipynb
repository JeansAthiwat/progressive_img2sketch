{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d573011b",
   "metadata": {},
   "source": [
    "# This notebook does the whole pipeline starting from the raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7ffdd",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c436d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\"  # must be set before importing pyrender\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import trimesh\n",
    "from trimesh.visual import ColorVisuals\n",
    "from trimesh.scene.lighting import DirectionalLight, PointLight\n",
    "\n",
    "import pyrender\n",
    "from pyrender import Primitive, Mesh as PyMesh, PerspectiveCamera, SpotLight, OffscreenRenderer\n",
    "from pyrender.constants import RenderFlags\n",
    "\n",
    "# test_mesh_path = \"/home/athiwat/progressive_img2sketch/resources/LOD50_opaque_normalized_triangulated/49/lod1.obj\"\n",
    "# trimesh_scene = trimesh.load(test_mesh_path)\n",
    "\n",
    "# print(trimesh_scene.vertices.shape)  # (#V, 3)\n",
    "# print(trimesh_scene.faces.shape)     # (#F, 3) — these are still triangles\n",
    "\n",
    "# trimesh_scene.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f07353",
   "metadata": {},
   "source": [
    "### 1. Correcting the UV Paths for the LOD dataset\n",
    "\n",
    "just need to run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3270772",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_Y_AXIS = True  # Set to True to visualize the Y-axis\n",
    "# RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD_for_icp\"\n",
    "\n",
    "\n",
    "# traverse_and_fix(RAW_LOD_DATASET_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf415ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def center_scene_by_bbox(scene: trimesh.Scene) -> trimesh.Scene:\n",
    "    \"\"\"\n",
    "    Center the scene at the origin based on its bounding-box center.\n",
    "    \"\"\"\n",
    "    min_corner, max_corner = scene.bounds\n",
    "    center = (min_corner + max_corner) / 2.0\n",
    "    scene.apply_translation(-center)\n",
    "    return scene\n",
    "\n",
    "def get_registration_matrix(\n",
    "    source_mesh: trimesh.Trimesh,\n",
    "    target_mesh: trimesh.Trimesh,\n",
    "    samples: int = 3000,\n",
    "    icp_first: int = 1,\n",
    "    icp_final: int = 30\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the ICP transformation matrix that aligns source_mesh to target_mesh.\n",
    "    \"\"\"\n",
    "    matrix, _ = trimesh.registration.mesh_other(\n",
    "        source_mesh,\n",
    "        target_mesh,\n",
    "        samples=samples,\n",
    "        scale=False,\n",
    "        icp_first=icp_first,\n",
    "        icp_final=icp_final\n",
    "    )\n",
    "    return matrix\n",
    "\n",
    "def align_lods(scenes: dict[int, trimesh.Scene], center_before: bool = False):\n",
    "    # — step 1: (optional) rough centering to help ICP converge —\n",
    "    if center_before:\n",
    "        for lod in scenes:\n",
    "            scenes[lod] = center_scene_by_bbox(scenes[lod])\n",
    "\n",
    "    # — step 2: extract single meshes for ICP —\n",
    "    \n",
    "    meshes = {\n",
    "        lod: trimesh.util.concatenate(list(scenes[lod].geometry.values()))\n",
    "        for lod in scenes\n",
    "    }\n",
    "\n",
    "    #show original bbox centers\n",
    "    for lod, mesh in meshes.items():\n",
    "        min_corner, max_corner = mesh.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} original center: {center}\")\n",
    "        \n",
    "    # ICP: 2→1 then 3→2\n",
    "    t2_1 = get_registration_matrix(meshes[2], meshes[1])\n",
    "    t3_2 = get_registration_matrix(meshes[3], meshes[2])\n",
    "\n",
    "    # apply those transforms\n",
    "    scenes[2].apply_transform(t2_1)\n",
    "    scenes[3].apply_transform(t2_1 @ t3_2)\n",
    "\n",
    "    # show aligned bbox centers\n",
    "    for lod, scene in scenes.items():\n",
    "        min_corner, max_corner = scene.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} aligned center: {center}\")\n",
    "    # — step 3: **final centering** based on aligned LOD1 bbox —\n",
    "    min1, max1 = scenes[1].bounds\n",
    "    center1 = (min1 + max1) * 0.5\n",
    "    for lod in scenes:\n",
    "        scenes[lod].apply_translation(-center1)\n",
    "\n",
    "    return scenes\n",
    "\n",
    "def look_at_matrix(eye: np.ndarray, target: np.ndarray, up: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a camera-to-world pose matrix for pyrender given eye, target, up vectors.\n",
    "    \"\"\"\n",
    "    f = (target - eye)\n",
    "    f /= np.linalg.norm(f)\n",
    "    # avoid parallel up/f\n",
    "    if np.isclose(np.linalg.norm(np.cross(f, up)), 0):\n",
    "        up = np.array([0, 0, 1]) if np.isclose(abs(f.dot([0, 1, 0])), 1) else np.array([0, 1, 0])\n",
    "    s = np.cross(f, up); s /= np.linalg.norm(s)\n",
    "    u = np.cross(s, f); u /= np.linalg.norm(u)\n",
    "\n",
    "    # view matrix (world→camera)\n",
    "    view = np.array([\n",
    "        [ s[0],  s[1],  s[2], -s.dot(eye)],\n",
    "        [ u[0],  u[1],  u[2], -u.dot(eye)],\n",
    "        [-f[0], -f[1], -f[2],  f.dot(eye)],\n",
    "        [    0,     0,     0,           1]\n",
    "    ])\n",
    "    # invert → camera pose (camera→world)\n",
    "    return np.linalg.inv(view)\n",
    "\n",
    "def align_lods_1_2_only(meshes: dict[int, trimesh.base.Trimesh], center_before: bool = False, samples: int = 3000):\n",
    "    # Show original bbox centers\n",
    "    for lod, mesh in [(1, meshes[1]), (2, meshes[2])]:\n",
    "        min_corner, max_corner = mesh.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} original center: {center}\")\n",
    "        \n",
    "    # — step 1: (optional) rough centering to help ICP converge —\n",
    "    if center_before:\n",
    "        for lod in [1, 2]:\n",
    "            meshes[lod] = center_scene_by_bbox(meshes[lod])\n",
    "\n",
    "    # — step 2: extract meshes —\n",
    "\n",
    "    mesh1 = meshes[1]\n",
    "    mesh2 = meshes[2]\n",
    "    # ICP: 2 → 1\n",
    "    t2_1 = get_registration_matrix(mesh2, mesh1, samples=samples)\n",
    "    meshes[2].apply_transform(t2_1)\n",
    "\n",
    "    # Show aligned bbox centers\n",
    "    for lod in [1, 2]:\n",
    "        min_corner, max_corner = meshes[lod].bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} aligned center: {center}\")\n",
    "\n",
    "    # — step 3: center both based on aligned LOD1 —\n",
    "    min1, max1 = meshes[1].bounds\n",
    "    center1 = (min1 + max1) * 0.5\n",
    "    for lod in [1, 2]:\n",
    "        meshes[lod].apply_translation(-center1)\n",
    "\n",
    "    return meshes\n",
    "\n",
    "def render_orbit_with_creases(mesh, line_mesh, lod_meshes, scene_number, lod, output_root,\n",
    "                               azimuths, elevations, width=2048, height=2048):\n",
    "    \"\"\"\n",
    "    Orbit render for one mesh+line using pyrender, transparent background.\n",
    "    \"\"\"\n",
    "    # Compute camera orbit radius\n",
    "    max_bbox = max([m.bounding_box.extents.max() for m in lod_meshes.values()])\n",
    "    radius = max_bbox * 1.5\n",
    "    target = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "\n",
    "    for az in azimuths:\n",
    "        for el in elevations:\n",
    "            # spherical → cartesian\n",
    "            rad_az = np.deg2rad(az)\n",
    "            rad_el = np.deg2rad(el)\n",
    "            x = radius * np.cos(rad_el) * np.sin(rad_az)\n",
    "            y = radius * np.sin(rad_el)\n",
    "            z = radius * np.cos(rad_el) * np.cos(rad_az)\n",
    "            eye = np.array([x, y, z])\n",
    "\n",
    "            # Setup scene\n",
    "            scene = pyrender.Scene()\n",
    "            # scene = pyrender.Scene(bg_color=[255, 255, 255, 0], ambient_light=[0.8, 0.8, 0.8])\n",
    "            \n",
    "            cam_pose = look_at_matrix(eye, target, up=np.array([0, 1, 0]))\n",
    "            camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=width / height)\n",
    "            scene.add(camera, pose=cam_pose)\n",
    "\n",
    "            # In your render_orbit_with_creases function, replace:\n",
    "            # mesh_tex = PyMesh.from_trimesh(mesh, smooth=True)\n",
    "\n",
    "            # With:\n",
    "            mesh_copy = mesh.copy()\n",
    "            # Force all materials to be opaque\n",
    "            if hasattr(mesh_copy.visual, 'material'):\n",
    "                mesh_copy.visual.material.alphaMode = 'OPAQUE'\n",
    "\n",
    "            mesh_tex = PyMesh.from_trimesh(mesh_copy, smooth=True)\n",
    "            scene.add(mesh_tex)\n",
    "            \n",
    "            if line_mesh is not None:\n",
    "                scene.add(line_mesh)\n",
    "\n",
    "            color, _ = renderer.render(scene, flags=RenderFlags.RGBA)\n",
    "\n",
    "            # Save to file\n",
    "            save_dir = os.path.join(output_root, str(scene_number), f\"lod{lod}\")\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            filename = f\"lod{lod}_az{az:03d}_el{el:02d}.png\"\n",
    "            save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "            if color.shape[-1] == 4:\n",
    "                Image.fromarray(color, mode=\"RGBA\").save(save_path)\n",
    "            elif color.shape[-1] == 3:\n",
    "                Image.fromarray(color, mode=\"RGB\").save(save_path)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected image shape: {color.shape}\")\n",
    "\n",
    "\n",
    "    renderer.delete()\n",
    "\n",
    "def line_segments_to_cylinders(vertices, edges, radius=0.1, sections=6):\n",
    "    cylinders = []\n",
    "    for edge in edges:\n",
    "        start = vertices[edge[0]]\n",
    "        end   = vertices[edge[1]]\n",
    "        direction = end - start\n",
    "        height = np.linalg.norm(direction)\n",
    "        if height < 1e-6:\n",
    "            continue\n",
    "\n",
    "        # Create a base cylinder aligned to z-axis\n",
    "        cyl = trimesh.creation.cylinder(radius=radius, height=height, sections=sections)\n",
    "        cyl.apply_translation([0, 0, height / 2.0])  # base at origin\n",
    "\n",
    "        # Rotate to align with actual direction\n",
    "        cyl.apply_transform(trimesh.geometry.align_vectors([0, 0, 1], direction))\n",
    "\n",
    "        # Translate to start point\n",
    "        cyl.apply_translation(start)\n",
    "\n",
    "        cylinders.append(cyl)\n",
    "\n",
    "    if not cylinders:\n",
    "        return None\n",
    "\n",
    "    # Combine all into one mesh\n",
    "    combined = trimesh.util.concatenate(cylinders)\n",
    "\n",
    "    # Assign black color (RGBA = 0,0,0,255) to each face\n",
    "    black_color = np.tile([0, 0, 0, 255], (len(combined.faces), 1))  # uint8 by default\n",
    "    combined.visual.face_colors = black_color\n",
    "\n",
    "    return pyrender.Mesh.from_trimesh(combined, smooth=False)\n",
    "\n",
    "def force_opaque_materials(mesh):\n",
    "    \"\"\"Force all materials to be opaque\"\"\"\n",
    "    if hasattr(mesh.visual, 'material'):\n",
    "        if hasattr(mesh.visual.material, 'diffuse'):\n",
    "            # Ensure alpha is 1.0 for diffuse color\n",
    "            if len(mesh.visual.material.diffuse) == 4:\n",
    "                mesh.visual.material.diffuse[3] = 0.0\n",
    "        if hasattr(mesh.visual.material, 'baseColorFactor'):\n",
    "            # For PBR materials\n",
    "            if len(mesh.visual.material.baseColorFactor) == 4:\n",
    "                mesh.visual.material.baseColorFactor[3] = 0.0\n",
    "\n",
    "def make_faces_opaque_preserve_texture(meshes):\n",
    "    \"\"\"\n",
    "    Sets alpha channel of face colors to 255 (opaque), preserving RGB values.\n",
    "    Works for both RGB and RGBA face color arrays.\n",
    "    \"\"\"\n",
    "    for lod, mesh in meshes.items():\n",
    "        print(f\"Processing LOD {lod} transparency...\")\n",
    "        \n",
    "        # Handle face colors\n",
    "        if hasattr(mesh.visual, 'face_colors') and mesh.visual.face_colors is not None:\n",
    "            fc = mesh.visual.face_colors\n",
    "            print(f\"  Face colors shape: {fc.shape}\")\n",
    "            \n",
    "            if fc.shape[1] == 4:\n",
    "                # Already RGBA, set alpha to 255\n",
    "                mesh.visual.face_colors[:, 3] = 255\n",
    "                print(f\"  Set alpha to 255 for {len(fc)} faces\")\n",
    "            elif fc.shape[1] == 3:\n",
    "                # RGB only, add alpha channel\n",
    "                alpha = np.full((fc.shape[0], 1), 255, dtype=fc.dtype)\n",
    "                mesh.visual.face_colors = np.hstack((fc, alpha))\n",
    "                print(f\"  Added alpha channel to {len(fc)} faces\")\n",
    "        \n",
    "        # Handle vertex colors if present\n",
    "        if hasattr(mesh.visual, 'vertex_colors') and mesh.visual.vertex_colors is not None:\n",
    "            vc = mesh.visual.vertex_colors\n",
    "            if vc.shape[1] == 4:\n",
    "                mesh.visual.vertex_colors[:, 3] = 255\n",
    "            elif vc.shape[1] == 3:\n",
    "                alpha = np.full((vc.shape[0], 1), 255, dtype=vc.dtype)\n",
    "                mesh.visual.vertex_colors = np.hstack((vc, alpha))\n",
    "        \n",
    "        # Force material opacity\n",
    "        force_opaque_materials(mesh)\n",
    "                \n",
    "def debug_face_colors(meshes):\n",
    "    \"\"\"Debug function to check face color transparency\"\"\"\n",
    "    for lod, mesh in meshes.items():\n",
    "        fc = getattr(mesh.visual, \"face_colors\", None)\n",
    "        if fc is not None:\n",
    "            print(f\"LOD {lod} face colors shape: {fc.shape}\")\n",
    "            print(f\"LOD {lod} alpha channel min/max: {fc[:, 3].min()}/{fc[:, 3].max()}\")\n",
    "            print(f\"LOD {lod} unique alpha values: {np.unique(fc[:, 3])}\")\n",
    "        else:\n",
    "            print(f\"LOD {lod} has no face colors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fcb28",
   "metadata": {},
   "source": [
    "### 2. Load the scene and orbit capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcde91a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOD 1 original center: [0.e+00 1.e-06 0.e+00]\n",
      "LOD 2 original center: [0.e+00 1.e-06 0.e+00]\n",
      "LOD 1 aligned center: [0. 0. 0.]\n",
      "LOD 2 aligned center: [-1.53834609 -0.14552135 -2.9632285 ]\n",
      "Processing LOD1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1869854/1130951449.py:180: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  Image.fromarray(color, mode=\"RGB\").save(save_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LOD2...\n",
      "LOD 1 original center: [0.e+00 5.e-07 0.e+00]\n",
      "LOD 2 original center: [ 0.00000000e+00 -5.00000001e-07  0.00000000e+00]\n",
      "LOD 1 aligned center: [0. 0. 0.]\n",
      "LOD 2 aligned center: [-0.01959294  0.65156799  0.01684448]\n",
      "Processing LOD1...\n",
      "Processing LOD2...\n",
      "LOD 1 original center: [0. 0. 0.]\n",
      "LOD 2 original center: [0. 0. 0.]\n",
      "LOD 1 aligned center: [0. 0. 0.]\n",
      "LOD 2 aligned center: [-0.00043213 -0.00210114 -0.00912404]\n",
      "Processing LOD1...\n",
      "Processing LOD2...\n",
      "LOD 1 original center: [0. 0. 0.]\n",
      "LOD 2 original center: [0. 0. 0.]\n",
      "LOD 1 aligned center: [0. 0. 0.]\n",
      "LOD 2 aligned center: [-0.03830383 -1.17018868 -1.00643318]\n",
      "Processing LOD1...\n",
      "Processing LOD2...\n",
      "LOD 1 original center: [ 0.e+00 -5.e-07  0.e+00]\n",
      "LOD 2 original center: [ 0.e+00 -5.e-07  0.e+00]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     lod_meshes[lod] \u001b[38;5;241m=\u001b[39m lod_mesh\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# ─── 2. Align meshes ──────────────────────────────────────────────\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m aligned_meshes \u001b[38;5;241m=\u001b[39m \u001b[43malign_lods_1_2_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlod_meshes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# ─── 2.1 Sanitize transparency ────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ─── 2.1 Sanitize transparency ────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# debug_face_colors(aligned_meshes)  # Debug first\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# make_faces_opaque_preserve_texture(aligned_meshes)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# debug_face_colors(aligned_meshes)  # Check after fix\u001b[39;00m\n\u001b[1;32m     34\u001b[0m scene \u001b[38;5;241m=\u001b[39m trimesh\u001b[38;5;241m.\u001b[39mScene()\n",
      "Cell \u001b[0;32mIn[3], line 109\u001b[0m, in \u001b[0;36malign_lods_1_2_only\u001b[0;34m(meshes, center_before, samples)\u001b[0m\n\u001b[1;32m    107\u001b[0m mesh2 \u001b[38;5;241m=\u001b[39m meshes[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# ICP: 2 → 1\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m t2_1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_registration_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m meshes[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mapply_transform(t2_1)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Show aligned bbox centers\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m, in \u001b[0;36mget_registration_matrix\u001b[0;34m(source_mesh, target_mesh, samples, icp_first, icp_final)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_registration_matrix\u001b[39m(\n\u001b[1;32m     11\u001b[0m     source_mesh: trimesh\u001b[38;5;241m.\u001b[39mTrimesh,\n\u001b[1;32m     12\u001b[0m     target_mesh: trimesh\u001b[38;5;241m.\u001b[39mTrimesh,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     icp_final: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     16\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    Compute the ICP transformation matrix that aligns source_mesh to target_mesh.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     matrix, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrimesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmesh_other\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43micp_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43micp_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43micp_final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43micp_final\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m matrix\n",
      "File \u001b[0;32m~/.conda/envs/athiwat_controlnet/lib/python3.10/site-packages/trimesh/registration.py:171\u001b[0m, in \u001b[0;36mmesh_other\u001b[0;34m(mesh, other, samples, scale, icp_first, icp_final, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     costs[i] \u001b[38;5;241m=\u001b[39m cost\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# run a final ICP refinement step\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m matrix, _junk, cost \u001b[38;5;241m=\u001b[39m \u001b[43micp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43micp_final\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# convert to per- point distance average\u001b[39;00m\n\u001b[1;32m    181\u001b[0m cost \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(points)\n",
      "File \u001b[0;32m~/.conda/envs/athiwat_controlnet/lib/python3.10/site-packages/trimesh/registration.py:377\u001b[0m, in \u001b[0;36micp\u001b[0;34m(a, b, initial, threshold, max_iterations, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iterations):\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# Closest point in b to each point in a\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_mesh:\n\u001b[0;32m--> 377\u001b[0m         closest, _distance, _faces \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnearest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_surface\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m         _distances, ix \u001b[38;5;241m=\u001b[39m btree\u001b[38;5;241m.\u001b[39mquery(a, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/athiwat_controlnet/lib/python3.10/site-packages/trimesh/constants.py:151\u001b[0m, in \u001b[0;36mlog_time.<locals>.timed\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtimed\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    150\u001b[0m     tic \u001b[38;5;241m=\u001b[39m now()\n\u001b[0;32m--> 151\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m executed in \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, now() \u001b[38;5;241m-\u001b[39m tic)\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/athiwat_controlnet/lib/python3.10/site-packages/trimesh/proximity.py:333\u001b[0m, in \u001b[0;36mProximityQuery.on_surface\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@log_time\u001b[39m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mon_surface\u001b[39m(\u001b[38;5;28mself\u001b[39m, points):\n\u001b[1;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    Given list of points, for each point find the closest point\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    on any triangle of the mesh.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m      Index of closest triangle for each point.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclosest_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/athiwat_controlnet/lib/python3.10/site-packages/trimesh/proximity.py:146\u001b[0m, in \u001b[0;36mclosest_point\u001b[0;34m(mesh, points)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints must be (n,3)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# do a tree- based query for faces near each point\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[43mnearby_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# view triangles as an ndarray so we don't have to recompute\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# the MD5 during all of the subsequent advanced indexing\u001b[39;00m\n\u001b[1;32m    149\u001b[0m triangles \u001b[38;5;241m=\u001b[39m mesh\u001b[38;5;241m.\u001b[39mtriangles\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39mndarray)\n",
      "File \u001b[0;32m~/.conda/envs/athiwat_controlnet/lib/python3.10/site-packages/trimesh/proximity.py:64\u001b[0m, in \u001b[0;36mnearby_faces\u001b[0;34m(mesh, points)\u001b[0m\n\u001b[1;32m     61\u001b[0m bounds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack((points \u001b[38;5;241m-\u001b[39m distance_vertex, points \u001b[38;5;241m+\u001b[39m distance_vertex))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# faces that intersect axis aligned bounding box\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(rtree\u001b[38;5;241m.\u001b[39mintersection(b)) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bounds]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m candidates\n",
      "File \u001b[0;32m~/.conda/envs/athiwat_controlnet/lib/python3.10/site-packages/trimesh/proximity.py:64\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m bounds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack((points \u001b[38;5;241m-\u001b[39m distance_vertex, points \u001b[38;5;241m+\u001b[39m distance_vertex))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# faces that intersect axis aligned bounding box\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(\u001b[43mrtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintersection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bounds]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m candidates\n",
      "File \u001b[0;32m~/.conda/envs/athiwat_controlnet/lib/python3.10/site-packages/rtree/index.py:826\u001b[0m, in \u001b[0;36mIndex.intersection\u001b[0;34m(self, coordinates, objects)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m objects:\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intersection_obj(coordinates, objects)\n\u001b[0;32m--> 826\u001b[0m p_mins, p_maxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coordinate_pointers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m p_num_results \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_uint64(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    830\u001b[0m it \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mpointer(ctypes\u001b[38;5;241m.\u001b[39mc_int64())\n",
      "File \u001b[0;32m~/.conda/envs/athiwat_controlnet/lib/python3.10/site-packages/rtree/index.py:355\u001b[0m, in \u001b[0;36mIndex.get_coordinate_pointers\u001b[0;34m(self, coordinates)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_coordinate_pointers\u001b[39m(\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m, coordinates: Sequence[\u001b[38;5;28mfloat\u001b[39m]\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    354\u001b[0m     dimension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mdimension\n\u001b[0;32m--> 355\u001b[0m     coordinates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m     arr \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_double \u001b[38;5;241m*\u001b[39m dimension\n\u001b[1;32m    358\u001b[0m     mins \u001b[38;5;241m=\u001b[39m arr()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ─── Config ───────────────────────────────────────────────────────\n",
    "# scene_num = 46\n",
    "\n",
    "threshold_degrees = 5.0\n",
    "angle_thresh = np.deg2rad(threshold_degrees)\n",
    "# RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD_data_50\"\n",
    "RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD50_opaque_normalized_triangulated\"\n",
    "\n",
    "SCENES = range(46, 51)  # Assuming scenes are numbered from 1 to 50\n",
    "LODS = [1, 2]\n",
    "\n",
    "for scene_num in SCENES:\n",
    "    # ─── 1. Load LOD meshes into dict ─────────────────────────────────\n",
    "    lod_meshes = {}\n",
    "    for lod in LODS:\n",
    "        path = os.path.join(RAW_LOD_DATASET_ROOT, str(scene_num), f\"lod{lod}.obj\")\n",
    "        loaded = trimesh.load(path, process=False)\n",
    "        lod_mesh = (\n",
    "            trimesh.util.concatenate(loaded.geometry.values())\n",
    "            if isinstance(loaded, trimesh.Scene)\n",
    "            else loaded\n",
    "        )\n",
    "        lod_meshes[lod] = lod_mesh\n",
    "\n",
    "    # ─── 2. Align meshes ──────────────────────────────────────────────\n",
    "    aligned_meshes = align_lods_1_2_only(lod_meshes, center_before=True, samples=4000)\n",
    "    \n",
    "    # ─── 2.1 Sanitize transparency ────────────────────────────────────\n",
    "    # ─── 2.1 Sanitize transparency ────────────────────────────────────\n",
    "    # debug_face_colors(aligned_meshes)  # Debug first\n",
    "    # make_faces_opaque_preserve_texture(aligned_meshes)\n",
    "    # debug_face_colors(aligned_meshes)  # Check after fix\n",
    "\n",
    "    scene = trimesh.Scene()\n",
    "    # # ─── 3. Build scene dict with crease lines ────────────────────────\n",
    "    scene_dict = {}\n",
    "    \n",
    "    for lod, mesh in aligned_meshes.items():\n",
    "        print(f\"Processing LOD{lod}...\")\n",
    "\n",
    "        # Step 1: Weld mesh for edge adjacency analysis\n",
    "        welded = trimesh.Trimesh(vertices=mesh.vertices.copy(),\n",
    "                                faces=mesh.faces.copy(),\n",
    "                                process=True)\n",
    "        # Step 2: Detect creases\n",
    "        fa = welded.face_adjacency_angles\n",
    "        edges = welded.face_adjacency_edges\n",
    "        mask = fa > angle_thresh\n",
    "        \n",
    "        # Filter to manifold edges only\n",
    "        from collections import defaultdict\n",
    "        edge_count = defaultdict(int)\n",
    "        for face in welded.faces:\n",
    "            for i in range(3):\n",
    "                e = tuple(sorted((face[i], face[(i+1)%3])))\n",
    "                edge_count[e] += 1\n",
    "        filtered_edges = [e for e in edges[mask] if edge_count[tuple(sorted(e))] == 2]\n",
    "\n",
    "        # Step 3: Create pyrender line mesh for rendering\n",
    "        line_mesh = line_segments_to_cylinders(welded.vertices, filtered_edges)\n",
    "\n",
    "        # Step 4: Render together with the mesh\n",
    "        AZIMUTH_STEP = 45\n",
    "        ELEVATIONS = [0, 30]\n",
    "        OUTPUT_ROOT = \"/home/athiwat/progressive_img2sketch/resources/test_orbit\"  # customize this\n",
    "\n",
    "        render_orbit_with_creases(\n",
    "            mesh=mesh,\n",
    "            line_mesh=line_mesh,\n",
    "            lod_meshes=aligned_meshes,\n",
    "            scene_number=scene_num,\n",
    "            lod=lod,\n",
    "            output_root=OUTPUT_ROOT,\n",
    "            azimuths=range(0, 360, AZIMUTH_STEP),\n",
    "            elevations=ELEVATIONS\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athiwat_controlnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
