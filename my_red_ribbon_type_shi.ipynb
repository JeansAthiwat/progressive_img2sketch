{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d573011b",
   "metadata": {},
   "source": [
    "# This notebook does the whole pipeline starting from the raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7ffdd",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c436d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\" # important to be set before importing pyrender\n",
    "\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "import matplotlib.pyplot as plt\n",
    "# from dataset_processing.fix_normal import traverse_and_fix\n",
    "from pyrender.constants import RenderFlags\n",
    "from PIL import Image\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from trimesh.visual import ColorVisuals\n",
    "from trimesh.scene.lighting import DirectionalLight, PointLight\n",
    "\n",
    "# sanity = trimesh.load(\"/home/athiwat/progressive_img2sketch/resources/LOD_for_icp/46/lod2.obj\", process=True)\n",
    "# # to mesh\n",
    "# if isinstance(sanity, trimesh.Scene):\n",
    "#     sanity = sanity.dump(concatenate=True)\n",
    "# trimesh.repair.fix_normals(sanity)\n",
    "# trimesh.repair.fix_inversion(sanity)\n",
    "# trimesh.repair.fix_winding(sanity)\n",
    "# trimesh.repair.broken_faces(sanity)\n",
    "# sanity.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f07353",
   "metadata": {},
   "source": [
    "### 1. Correcting the UV Paths for the LOD dataset\n",
    "\n",
    "just need to run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3270772",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_Y_AXIS = True  # Set to True to visualize the Y-axis\n",
    "RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD_for_icp\"\n",
    "\n",
    "# traverse_and_fix(RAW_LOD_DATASET_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf415ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_scene_by_bbox(scene: trimesh.Scene) -> trimesh.Scene:\n",
    "    \"\"\"\n",
    "    Center the scene at the origin based on its bounding-box center.\n",
    "    \"\"\"\n",
    "    min_corner, max_corner = scene.bounds\n",
    "    center = (min_corner + max_corner) / 2.0\n",
    "    scene.apply_translation(-center)\n",
    "    return scene\n",
    "\n",
    "def get_registration_matrix(\n",
    "    source_mesh: trimesh.Trimesh,\n",
    "    target_mesh: trimesh.Trimesh,\n",
    "    samples: int = 3000,\n",
    "    icp_first: int = 1,\n",
    "    icp_final: int = 30\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the ICP transformation matrix that aligns source_mesh to target_mesh.\n",
    "    \"\"\"\n",
    "    matrix, _ = trimesh.registration.mesh_other(\n",
    "        source_mesh,\n",
    "        target_mesh,\n",
    "        samples=samples,\n",
    "        scale=False,\n",
    "        icp_first=icp_first,\n",
    "        icp_final=icp_final\n",
    "    )\n",
    "    return matrix\n",
    "\n",
    "def align_lods(scenes: dict[int, trimesh.Scene], center_before: bool = False):\n",
    "    # — step 1: (optional) rough centering to help ICP converge —\n",
    "    if center_before:\n",
    "        for lod in scenes:\n",
    "            scenes[lod] = center_scene_by_bbox(scenes[lod])\n",
    "\n",
    "    # — step 2: extract single meshes for ICP —\n",
    "    \n",
    "    meshes = {\n",
    "        lod: trimesh.util.concatenate(list(scenes[lod].geometry.values()))\n",
    "        for lod in scenes\n",
    "    }\n",
    "\n",
    "    #show original bbox centers\n",
    "    for lod, mesh in meshes.items():\n",
    "        min_corner, max_corner = mesh.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} original center: {center}\")\n",
    "        \n",
    "    # ICP: 2→1 then 3→2\n",
    "    t2_1 = get_registration_matrix(meshes[2], meshes[1])\n",
    "    t3_2 = get_registration_matrix(meshes[3], meshes[2])\n",
    "\n",
    "    # apply those transforms\n",
    "    scenes[2].apply_transform(t2_1)\n",
    "    scenes[3].apply_transform(t2_1 @ t3_2)\n",
    "\n",
    "    # show aligned bbox centers\n",
    "    for lod, scene in scenes.items():\n",
    "        min_corner, max_corner = scene.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} aligned center: {center}\")\n",
    "    # — step 3: **final centering** based on aligned LOD1 bbox —\n",
    "    min1, max1 = scenes[1].bounds\n",
    "    center1 = (min1 + max1) * 0.5\n",
    "    for lod in scenes:\n",
    "        scenes[lod].apply_translation(-center1)\n",
    "\n",
    "    return scenes\n",
    "\n",
    "def look_at_matrix(eye: np.ndarray, target: np.ndarray, up: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a camera-to-world pose matrix for pyrender given eye, target, up vectors.\n",
    "    \"\"\"\n",
    "    f = (target - eye)\n",
    "    f /= np.linalg.norm(f)\n",
    "    # avoid parallel up/f\n",
    "    if np.isclose(np.linalg.norm(np.cross(f, up)), 0):\n",
    "        up = np.array([0, 0, 1]) if np.isclose(abs(f.dot([0, 1, 0])), 1) else np.array([0, 1, 0])\n",
    "    s = np.cross(f, up); s /= np.linalg.norm(s)\n",
    "    u = np.cross(s, f); u /= np.linalg.norm(u)\n",
    "\n",
    "    # view matrix (world→camera)\n",
    "    view = np.array([\n",
    "        [ s[0],  s[1],  s[2], -s.dot(eye)],\n",
    "        [ u[0],  u[1],  u[2], -u.dot(eye)],\n",
    "        [-f[0], -f[1], -f[2],  f.dot(eye)],\n",
    "        [    0,     0,     0,           1]\n",
    "    ])\n",
    "    # invert → camera pose (camera→world)\n",
    "    return np.linalg.inv(view)\n",
    "\n",
    "def align_lods_1_2_only(meshes: dict[int, trimesh.base.Trimesh], center_before: bool = False, samples: int = 3000):\n",
    "    # Show original bbox centers\n",
    "    for lod, mesh in [(1, meshes[1]), (2, meshes[2])]:\n",
    "        min_corner, max_corner = mesh.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} original center: {center}\")\n",
    "        \n",
    "    # — step 1: (optional) rough centering to help ICP converge —\n",
    "    if center_before:\n",
    "        for lod in [1, 2]:\n",
    "            meshes[lod] = center_scene_by_bbox(meshes[lod])\n",
    "\n",
    "    # — step 2: extract meshes —\n",
    "\n",
    "    mesh1 = meshes[1]\n",
    "    mesh2 = meshes[2]\n",
    "    # ICP: 2 → 1\n",
    "    t2_1 = get_registration_matrix(mesh2, mesh1, samples=samples)\n",
    "    meshes[2].apply_transform(t2_1)\n",
    "\n",
    "    # Show aligned bbox centers\n",
    "    for lod in [1, 2]:\n",
    "        min_corner, max_corner = meshes[lod].bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} aligned center: {center}\")\n",
    "\n",
    "    # — step 3: center both based on aligned LOD1 —\n",
    "    min1, max1 = meshes[1].bounds\n",
    "    center1 = (min1 + max1) * 0.5\n",
    "    for lod in [1, 2]:\n",
    "        meshes[lod].apply_translation(-center1)\n",
    "\n",
    "    return meshes\n",
    "\n",
    "\n",
    "\n",
    "def render_orbit_with_creases(mesh, line_mesh, lod_meshes, scene_number, lod, output_root,\n",
    "                               azimuths, elevations, width=2048, height=2048):\n",
    "    \"\"\"\n",
    "    Orbit render for one mesh+line using pyrender, transparent background.\n",
    "    \"\"\"\n",
    "    # Compute camera orbit radius\n",
    "    max_bbox = max([m.bounding_box.extents.max() for m in lod_meshes.values()])\n",
    "    radius = max_bbox * 1.5\n",
    "    target = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "\n",
    "    for az in azimuths:\n",
    "        for el in elevations:\n",
    "            # spherical → cartesian\n",
    "            rad_az = np.deg2rad(az)\n",
    "            rad_el = np.deg2rad(el)\n",
    "            x = radius * np.cos(rad_el) * np.sin(rad_az)\n",
    "            y = radius * np.sin(rad_el)\n",
    "            z = radius * np.cos(rad_el) * np.cos(rad_az)\n",
    "            eye = np.array([x, y, z])\n",
    "\n",
    "            # Setup scene\n",
    "            scene = pyrender.Scene(bg_color=[255, 255, 255, 0], ambient_light=[0.8, 0.8, 0.8])\n",
    "            cam_pose = look_at_matrix(eye, target, up=np.array([0, 1, 0]))\n",
    "            camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=width / height)\n",
    "            scene.add(camera, pose=cam_pose)\n",
    "\n",
    "            mesh_tex = PyMesh.from_trimesh(mesh, smooth=True)\n",
    "            scene.add(mesh_tex)\n",
    "            if line_mesh is not None:\n",
    "                scene.add(line_mesh)\n",
    "\n",
    "            color, _ = renderer.render(scene, flags=RenderFlags.RGBA)\n",
    "\n",
    "            # Save to file\n",
    "            save_dir = os.path.join(output_root, str(scene_number), f\"lod{lod}\")\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            filename = f\"lod{lod}_az{az:03d}_el{el:02d}.png\"\n",
    "            save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "            if color.shape[-1] == 4:\n",
    "                Image.fromarray(color, mode=\"RGBA\").save(save_path)\n",
    "            elif color.shape[-1] == 3:\n",
    "                Image.fromarray(color, mode=\"RGB\").save(save_path)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected image shape: {color.shape}\")\n",
    "\n",
    "\n",
    "    renderer.delete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fcb28",
   "metadata": {},
   "source": [
    "### 2. Load the scene and orbit capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde91a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check type of lod_meshes[1]: <class 'trimesh.base.Trimesh'>\n",
      "check type of lod_meshes[2]: <class 'trimesh.base.Trimesh'>\n",
      "LOD 1 original center: [ 7.10542736e-15 -4.44089210e-16  7.10542736e-15]\n",
      "LOD 2 original center: [7.10542736e-15 0.00000000e+00 7.10542736e-15]\n",
      "LOD 1 aligned center: [ 7.10542736e-15 -4.44089210e-16  7.10542736e-15]\n",
      "LOD 2 aligned center: [-0.04854708 -0.20025689 -0.0676345 ]\n",
      "Processing LOD1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1737426/3826413096.py:172: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  Image.fromarray(color, mode=\"RGB\").save(save_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LOD2...\n"
     ]
    }
   ],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ─── Config ───────────────────────────────────────────────────────\n",
    "scene_num = 46\n",
    "LODS = [1, 2]\n",
    "threshold_degrees = 5.0\n",
    "angle_thresh = np.deg2rad(threshold_degrees)\n",
    "# RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD_data_50\"\n",
    "RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD_for_icp\"\n",
    "\n",
    "# ─── 1. Load LOD meshes into dict ─────────────────────────────────\n",
    "lod_meshes = {}\n",
    "for lod in LODS:\n",
    "    path = os.path.join(RAW_LOD_DATASET_ROOT, str(scene_num), f\"lod{lod}.obj\")\n",
    "    loaded = trimesh.load(path, process=False)\n",
    "    mesh = (\n",
    "        trimesh.util.concatenate(loaded.geometry.values())\n",
    "        if isinstance(loaded, trimesh.Scene)\n",
    "        else loaded\n",
    "    )\n",
    "    lod_meshes[lod] = mesh\n",
    "\n",
    "print(f\"check type of lod_meshes[1]: {type(lod_meshes[1])}\")\n",
    "print(f\"check type of lod_meshes[2]: {type(lod_meshes[2])}\")\n",
    "# ─── 2. Align meshes ──────────────────────────────────────────────\n",
    "aligned_meshes = align_lods_1_2_only(lod_meshes, center_before=True, samples=4000)\n",
    "\n",
    "# ─── 2.1 Sanitize transparency ────────────────────────────────────\n",
    "for m in aligned_meshes.values():\n",
    "    if hasattr(m.visual, \"vertex_colors\") and m.visual.vertex_colors.shape[1] == 4:\n",
    "        m.visual.vertex_colors[:, 3] = 255\n",
    "    if hasattr(m.visual, \"face_colors\") and m.visual.face_colors.shape[1] == 4:\n",
    "        m.visual.face_colors[:, 3] = 255\n",
    "\n",
    "# aligned_meshes = lod_meshes.copy()\n",
    "scene = trimesh.Scene()\n",
    "# for lod, mesh in aligned_meshes.items():\n",
    "#     scene.add_geometry(mesh, geom_name=f\"LOD{lod}\")\n",
    "# scene.add_geometry(aligned_meshes[2], geom_name=\"LOD1\")\n",
    "\n",
    "# scene.show()\n",
    "# # ─── 3. Build scene dict with crease lines ────────────────────────\n",
    "scene_dict = {}\n",
    "import pyrender\n",
    "from pyrender import Primitive, Mesh as PyMesh, PerspectiveCamera, SpotLight, OffscreenRenderer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_line_primitive(vertices, edges):\n",
    "    \"\"\"\n",
    "    Create a pyrender.Mesh primitive from line segments.\n",
    "    \"\"\"\n",
    "    if len(edges) == 0:\n",
    "        return None\n",
    "\n",
    "    segments = vertices[np.array(edges)]  # shape (N, 2, 3)\n",
    "    pos = segments.reshape(-1, 3)         # flatten (N*2, 3)\n",
    "    idx = np.arange(len(pos)).reshape(-1, 2)\n",
    "\n",
    "    color = np.tile([0.0, 0.0, 0.0, 1.0], (pos.shape[0], 1))  # RGBA\n",
    "    prim = Primitive(positions=pos, indices=idx, mode=1, color_0=color)\n",
    "    return PyMesh(primitives=[prim])\n",
    "\n",
    "def render_with_creases(mesh, line_mesh, lod_meshes: dict, width=800, height=600):\n",
    "    \"\"\"\n",
    "    Render both a textured mesh and a line primitive with Raymond lighting,\n",
    "    placing the camera based on the maximum bounding box from all LODs.\n",
    "    \"\"\"\n",
    "    scene = pyrender.Scene(bg_color=[255, 255, 255, 0], ambient_light=[0.8, 0.8, 0.8])\n",
    "\n",
    "    # 1. Mesh (smooth shaded)\n",
    "    mesh_tex = pyrender.Mesh.from_trimesh(mesh, smooth=True)\n",
    "    scene.add(mesh_tex)\n",
    "\n",
    "    # 2. Line overlay\n",
    "    if line_mesh is not None:\n",
    "        scene.add(line_mesh)\n",
    "\n",
    "    # 3. Compute max bounding box across all LODs for orbit radius\n",
    "    max_bbox = max([m.bounding_box.extents.max() for m in lod_meshes.values()])\n",
    "    radius = max_bbox * 1.5  # Slightly back off\n",
    "\n",
    "    # 4. Define camera position from spherical coords\n",
    "    azimuth = np.deg2rad(45)  # or random/viewable angle\n",
    "    elevation = np.deg2rad(30)\n",
    "\n",
    "    x = radius * np.cos(elevation) * np.sin(azimuth)\n",
    "    y = radius * np.sin(elevation)\n",
    "    z = radius * np.cos(elevation) * np.cos(azimuth)\n",
    "    eye = np.array([x, y, z])\n",
    "    target = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    # 5. Setup camera + pose\n",
    "    cam_pose = look_at_matrix(eye, target, up=np.array([0, 1, 0]))\n",
    "    camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=width / height)\n",
    "    scene.add(camera, pose=cam_pose)\n",
    "\n",
    "    # 7. Render\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "    color, depth = renderer.render(scene)\n",
    "    renderer.delete()\n",
    "\n",
    "    return color, depth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ─── Main Processing Loop ───────────────────────────────────────\n",
    "for lod, mesh in aligned_meshes.items():\n",
    "    print(f\"Processing LOD{lod}...\")\n",
    "\n",
    "    # Step 1: Weld mesh for edge adjacency analysis\n",
    "    welded = trimesh.Trimesh(vertices=mesh.vertices.copy(),\n",
    "                             faces=mesh.faces.copy(),\n",
    "                             process=True)\n",
    "\n",
    "    # Step 2: Detect creases\n",
    "    fa = welded.face_adjacency_angles\n",
    "    edges = welded.face_adjacency_edges\n",
    "    mask = fa > angle_thresh\n",
    "\n",
    "    # Filter to manifold edges only\n",
    "    from collections import defaultdict\n",
    "    edge_count = defaultdict(int)\n",
    "    for face in welded.faces:\n",
    "        for i in range(3):\n",
    "            e = tuple(sorted((face[i], face[(i+1)%3])))\n",
    "            edge_count[e] += 1\n",
    "    filtered_edges = [e for e in edges[mask] if edge_count[tuple(sorted(e))] == 2]\n",
    "\n",
    "    # Step 3: Create pyrender line primitive\n",
    "    line_mesh = create_line_primitive(welded.vertices, filtered_edges)\n",
    "\n",
    "    # Step 4: Render together with the mesh\n",
    "    AZIMUTH_STEP = 45\n",
    "    ELEVATIONS = [0, 30]\n",
    "    OUTPUT_ROOT = \"/home/athiwat/progressive_img2sketch/resources/test_orbit\"  # customize this\n",
    "\n",
    "    render_orbit_with_creases(\n",
    "        mesh=mesh,\n",
    "        line_mesh=line_mesh,\n",
    "        lod_meshes=lod_meshes,\n",
    "        scene_number=scene_num,\n",
    "        lod=lod,\n",
    "        output_root=OUTPUT_ROOT,\n",
    "        azimuths=range(0, 360, AZIMUTH_STEP),\n",
    "        elevations=ELEVATIONS\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athiwat_controlnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
