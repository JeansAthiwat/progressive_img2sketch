{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d573011b",
   "metadata": {},
   "source": [
    "# This notebook does the whole pipeline starting from the raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7ffdd",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\"  # must be set before importing pyrender\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import trimesh\n",
    "from trimesh.visual import ColorVisuals\n",
    "from trimesh.scene.lighting import DirectionalLight, PointLight\n",
    "\n",
    "import pyrender\n",
    "from pyrender import Primitive, Mesh as PyMesh, PerspectiveCamera, SpotLight, OffscreenRenderer\n",
    "from pyrender.constants import RenderFlags\n",
    "from pyrender import MetallicRoughnessMaterial\n",
    "# test_mesh_path = \"/home/athiwat/progressive_img2sketch/fix_normal_recalculate_outside_test.obj\"\n",
    "# trimesh_scene = trimesh.load(test_mesh_path)\n",
    "\n",
    "# # print(trimesh_scene.vertices.shape)  # (#V, 3)\n",
    "# # print(trimesh_scene.faces.shape)     # (#F, 3) — these are still triangles\n",
    "\n",
    "# trimesh_scene.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f07353",
   "metadata": {},
   "source": [
    "### 1. Correcting the UV Paths for the LOD dataset\n",
    "\n",
    "just need to run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3270772",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_Y_AXIS = True  # Set to True to visualize the Y-axis\n",
    "# RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD_for_icp\"\n",
    "\n",
    "\n",
    "# traverse_and_fix(RAW_LOD_DATASET_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf415ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def center_scene_by_bbox(scene: trimesh.Scene) -> trimesh.Scene:\n",
    "    \"\"\"\n",
    "    Center the scene at the origin based on its bounding-box center.\n",
    "    \"\"\"\n",
    "    min_corner, max_corner = scene.bounds\n",
    "    center = (min_corner + max_corner) / 2.0\n",
    "    scene.apply_translation(-center)\n",
    "    return scene\n",
    "\n",
    "def get_registration_matrix(\n",
    "    source_mesh: trimesh.Trimesh,\n",
    "    target_mesh: trimesh.Trimesh,\n",
    "    samples: int = 3000,\n",
    "    icp_first: int = 1,\n",
    "    icp_final: int = 30\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the ICP transformation matrix that aligns source_mesh to target_mesh.\n",
    "    \"\"\"\n",
    "    matrix, _ = trimesh.registration.mesh_other(\n",
    "        source_mesh,\n",
    "        target_mesh,\n",
    "        samples=samples,\n",
    "        scale=False,\n",
    "        icp_first=icp_first,\n",
    "        icp_final=icp_final\n",
    "    )\n",
    "    return matrix\n",
    "\n",
    "def align_lods(scenes: dict[int, trimesh.Scene], center_before: bool = False):\n",
    "    # — step 1: (optional) rough centering to help ICP converge —\n",
    "    if center_before:\n",
    "        for lod in scenes:\n",
    "            scenes[lod] = center_scene_by_bbox(scenes[lod])\n",
    "\n",
    "    # — step 2: extract single meshes for ICP —\n",
    "    \n",
    "    meshes = {\n",
    "        lod: trimesh.util.concatenate(list(scenes[lod].geometry.values()))\n",
    "        for lod in scenes\n",
    "    }\n",
    "\n",
    "    #show original bbox centers\n",
    "    for lod, mesh in meshes.items():\n",
    "        min_corner, max_corner = mesh.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} original center: {center}\")\n",
    "        \n",
    "    # ICP: 2→1 then 3→2\n",
    "    t2_1 = get_registration_matrix(meshes[2], meshes[1])\n",
    "    t3_2 = get_registration_matrix(meshes[3], meshes[2])\n",
    "\n",
    "    # apply those transforms\n",
    "    scenes[2].apply_transform(t2_1)\n",
    "    scenes[3].apply_transform(t2_1 @ t3_2)\n",
    "\n",
    "    # show aligned bbox centers\n",
    "    for lod, scene in scenes.items():\n",
    "        min_corner, max_corner = scene.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} aligned center: {center}\")\n",
    "    # — step 3: **final centering** based on aligned LOD1 bbox —\n",
    "    min1, max1 = scenes[1].bounds\n",
    "    center1 = (min1 + max1) * 0.5\n",
    "    for lod in scenes:\n",
    "        scenes[lod].apply_translation(-center1)\n",
    "\n",
    "    return scenes\n",
    "\n",
    "def look_at_matrix(eye: np.ndarray, target: np.ndarray, up: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a camera-to-world pose matrix for pyrender given eye, target, up vectors.\n",
    "    \"\"\"\n",
    "    f = (target - eye)\n",
    "    f /= np.linalg.norm(f)\n",
    "    # avoid parallel up/f\n",
    "    if np.isclose(np.linalg.norm(np.cross(f, up)), 0):\n",
    "        up = np.array([0, 0, 1]) if np.isclose(abs(f.dot([0, 1, 0])), 1) else np.array([0, 1, 0])\n",
    "    s = np.cross(f, up); s /= np.linalg.norm(s)\n",
    "    u = np.cross(s, f); u /= np.linalg.norm(u)\n",
    "\n",
    "    # view matrix (world→camera)\n",
    "    view = np.array([\n",
    "        [ s[0],  s[1],  s[2], -s.dot(eye)],\n",
    "        [ u[0],  u[1],  u[2], -u.dot(eye)],\n",
    "        [-f[0], -f[1], -f[2],  f.dot(eye)],\n",
    "        [    0,     0,     0,           1]\n",
    "    ])\n",
    "    # invert → camera pose (camera→world)\n",
    "    return np.linalg.inv(view)\n",
    "\n",
    "def align_lods_1_2_only(meshes: dict[int, trimesh.base.Trimesh], center_before: bool = False, samples: int = 3000):\n",
    "    # Show original bbox centers\n",
    "    for lod, mesh in [(1, meshes[1]), (2, meshes[2])]:\n",
    "        min_corner, max_corner = mesh.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} original center: {center}\")\n",
    "        \n",
    "    # — step 1: (optional) rough centering to help ICP converge —\n",
    "    if center_before:\n",
    "        for lod in [1, 2]:\n",
    "            meshes[lod] = center_scene_by_bbox(meshes[lod])\n",
    "\n",
    "    # — step 2: extract meshes —\n",
    "\n",
    "    mesh1 = meshes[1]\n",
    "    mesh2 = meshes[2]\n",
    "    # ICP: 2 → 1\n",
    "    t2_1 = get_registration_matrix(mesh2, mesh1, samples=samples)\n",
    "    meshes[2].apply_transform(t2_1)\n",
    "\n",
    "    # Show aligned bbox centers\n",
    "    for lod in [1, 2]:\n",
    "        min_corner, max_corner = meshes[lod].bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} aligned center: {center}\")\n",
    "\n",
    "    # — step 3: center both based on aligned LOD1 —\n",
    "    min1, max1 = meshes[1].bounds\n",
    "    center1 = (min1 + max1) * 0.5\n",
    "    for lod in [1, 2]:\n",
    "        meshes[lod].apply_translation(-center1)\n",
    "\n",
    "    return meshes\n",
    "\n",
    "def render_orbit_with_creases(mesh, line_mesh, lod_meshes, scene_number, lod, output_root,\n",
    "                               azimuths, elevations, width=2048, height=2048):\n",
    "    \"\"\"\n",
    "    Orbit render for one mesh+line using pyrender, transparent background.\n",
    "    \"\"\"\n",
    "    # Compute camera orbit radius\n",
    "    max_bbox = max([m.bounding_box.extents.max() for m in lod_meshes.values()])\n",
    "    radius = max_bbox * 1.5\n",
    "    target = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    renderer = pyrender.OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "\n",
    "    for az in azimuths:\n",
    "        for el in elevations:\n",
    "            # spherical → cartesian\n",
    "            rad_az = np.deg2rad(az)\n",
    "            rad_el = np.deg2rad(el)\n",
    "            x = radius * np.cos(rad_el) * np.sin(rad_az)\n",
    "            y = radius * np.sin(rad_el)\n",
    "            z = radius * np.cos(rad_el) * np.cos(rad_az)\n",
    "            eye = np.array([x, y, z])\n",
    "\n",
    "            # Setup scene\n",
    "            scene = pyrender.Scene(bg_color=[255, 255, 255, 0], ambient_light=[0.8, 0.8, 0.8])\n",
    "            # add reymond light\n",
    "            # —– add Raymond lighting —–\n",
    "            intensity = 10.0\n",
    "\n",
    "            key = pyrender.DirectionalLight(color=np.ones(3), intensity=intensity)\n",
    "            key_pose = np.array([\n",
    "                [ 0,  0,  1,  2],\n",
    "                [ 0,  1,  0,  2],\n",
    "                [ 1,  0,  0,  2],\n",
    "                [ 0,  0,  0,  1],\n",
    "            ])\n",
    "            scene.add(key, pose=key_pose)\n",
    "\n",
    "            fill = pyrender.DirectionalLight(color=np.ones(3), intensity=intensity * 0.75)\n",
    "            fill_pose = np.array([\n",
    "                [ 0,  0, -1, -2],\n",
    "                [ 0,  1,  0,  1],\n",
    "                [-1,  0,  0, -2],\n",
    "                [ 0,  0,  0,  1],\n",
    "            ])\n",
    "            scene.add(fill, pose=fill_pose)\n",
    "\n",
    "            back = pyrender.DirectionalLight(color=np.ones(3), intensity=intensity * 0.5)\n",
    "            back_pose = np.array([\n",
    "                [ 1,  0,  0, -2],\n",
    "                [ 0,  0,  1, -2],\n",
    "                [ 0,  1,  0,  2],\n",
    "                [ 0,  0,  0,  1],\n",
    "            ])\n",
    "            scene.add(back, pose=back_pose)\n",
    "            \n",
    "            cam_pose = look_at_matrix(eye, target, up=np.array([0, 1, 0]))\n",
    "            camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=width / height)\n",
    "            scene.add(camera, pose=cam_pose)\n",
    "\n",
    "            # In your render_orbit_with_creases function, replace:\n",
    "            # mesh_tex = PyMesh.from_trimesh(mesh, smooth=True)\n",
    "\n",
    "            # With:\n",
    "            mesh_copy = mesh.copy()\n",
    "            # Force all materials to be opaque\n",
    "            if hasattr(mesh_copy.visual, 'material'):\n",
    "                mesh_copy.visual.material.alphaMode = 'OPAQUE'\n",
    "\n",
    "            mesh_tex = PyMesh.from_trimesh(mesh_copy, smooth=False)\n",
    "            scene.add(mesh_tex)\n",
    "            \n",
    "            if line_mesh is not None:\n",
    "                scene.add(line_mesh)\n",
    "\n",
    "            color, _ = renderer.render(scene, flags=RenderFlags.RGBA)\n",
    "\n",
    "            # Save to file\n",
    "            save_dir = os.path.join(output_root, str(scene_number), f\"lod{lod}\")\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            filename = f\"lod{lod}_az{az:03d}_el{el:02d}.png\"\n",
    "            save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "            if color.shape[-1] == 4:\n",
    "                Image.fromarray(color, mode=\"RGBA\").save(save_path)\n",
    "            elif color.shape[-1] == 3:\n",
    "                Image.fromarray(color, mode=\"RGB\").save(save_path)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected image shape: {color.shape}\")\n",
    "\n",
    "\n",
    "    renderer.delete()\n",
    "\n",
    "def line_segments_to_cylinders(vertices, edges, radius=0.001, sections=6):\n",
    "    cylinders = []\n",
    "    for edge in edges:\n",
    "        start = vertices[edge[0]]\n",
    "        end   = vertices[edge[1]]\n",
    "        direction = end - start\n",
    "        height = np.linalg.norm(direction)\n",
    "        if height < 1e-6:\n",
    "            continue\n",
    "\n",
    "        # Create a base cylinder aligned to z-axis\n",
    "        cyl = trimesh.creation.cylinder(radius=radius, height=height, sections=sections)\n",
    "        cyl.apply_translation([0, 0, height / 2.0])  # base at origin\n",
    "\n",
    "        # Rotate to align with actual direction\n",
    "        cyl.apply_transform(trimesh.geometry.align_vectors([0, 0, 1], direction))\n",
    "\n",
    "        # Translate to start point\n",
    "        cyl.apply_translation(start)\n",
    "\n",
    "        cylinders.append(cyl)\n",
    "\n",
    "    if not cylinders:\n",
    "        return None\n",
    "\n",
    "    # Combine all into one mesh\n",
    "    combined = trimesh.util.concatenate(cylinders)\n",
    "\n",
    "    # Assign black color (RGBA = 0,0,0,255) to each face\n",
    "    black_color = np.tile([0, 0, 0, 255], (len(combined.faces), 1))  # uint8 by default\n",
    "    combined.visual.face_colors = black_color\n",
    "\n",
    "    return pyrender.Mesh.from_trimesh(combined, smooth=False)\n",
    "\n",
    "def force_opaque_materials(mesh):\n",
    "    \"\"\"Force all materials to be opaque\"\"\"\n",
    "    if hasattr(mesh.visual, 'material'):\n",
    "        if hasattr(mesh.visual.material, 'diffuse'):\n",
    "            # Ensure alpha is 1.0 for diffuse color\n",
    "            if len(mesh.visual.material.diffuse) == 4:\n",
    "                mesh.visual.material.diffuse[3] = 0.0\n",
    "        if hasattr(mesh.visual.material, 'baseColorFactor'):\n",
    "            # For PBR materials\n",
    "            if len(mesh.visual.material.baseColorFactor) == 4:\n",
    "                mesh.visual.material.baseColorFactor[3] = 0.0\n",
    "\n",
    "def make_faces_opaque_preserve_texture(meshes):\n",
    "    \"\"\"\n",
    "    Sets alpha channel of face colors to 255 (opaque), preserving RGB values.\n",
    "    Works for both RGB and RGBA face color arrays.\n",
    "    \"\"\"\n",
    "    for lod, mesh in meshes.items():\n",
    "        print(f\"Processing LOD {lod} transparency...\")\n",
    "        \n",
    "        # Handle face colors\n",
    "        if hasattr(mesh.visual, 'face_colors') and mesh.visual.face_colors is not None:\n",
    "            fc = mesh.visual.face_colors\n",
    "            print(f\"  Face colors shape: {fc.shape}\")\n",
    "            \n",
    "            if fc.shape[1] == 4:\n",
    "                # Already RGBA, set alpha to 255\n",
    "                mesh.visual.face_colors[:, 3] = 255\n",
    "                print(f\"  Set alpha to 255 for {len(fc)} faces\")\n",
    "            elif fc.shape[1] == 3:\n",
    "                # RGB only, add alpha channel\n",
    "                alpha = np.full((fc.shape[0], 1), 255, dtype=fc.dtype)\n",
    "                mesh.visual.face_colors = np.hstack((fc, alpha))\n",
    "                print(f\"  Added alpha channel to {len(fc)} faces\")\n",
    "        \n",
    "        # Handle vertex colors if present\n",
    "        if hasattr(mesh.visual, 'vertex_colors') and mesh.visual.vertex_colors is not None:\n",
    "            vc = mesh.visual.vertex_colors\n",
    "            if vc.shape[1] == 4:\n",
    "                mesh.visual.vertex_colors[:, 3] = 255\n",
    "            elif vc.shape[1] == 3:\n",
    "                alpha = np.full((vc.shape[0], 1), 255, dtype=vc.dtype)\n",
    "                mesh.visual.vertex_colors = np.hstack((vc, alpha))\n",
    "        \n",
    "        # Force material opacity\n",
    "        force_opaque_materials(mesh)\n",
    "                \n",
    "def debug_face_colors(meshes):\n",
    "    \"\"\"Debug function to check face color transparency\"\"\"\n",
    "    for lod, mesh in meshes.items():\n",
    "        fc = getattr(mesh.visual, \"face_colors\", None)\n",
    "        if fc is not None:\n",
    "            print(f\"LOD {lod} face colors shape: {fc.shape}\")\n",
    "            print(f\"LOD {lod} alpha channel min/max: {fc[:, 3].min()}/{fc[:, 3].max()}\")\n",
    "            print(f\"LOD {lod} unique alpha values: {np.unique(fc[:, 3])}\")\n",
    "        else:\n",
    "            print(f\"LOD {lod} has no face colors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fcb28",
   "metadata": {},
   "source": [
    "### 2. Load the scene and orbit capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcde91a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOD 1 original center: [0. 0. 0.]\n",
      "LOD 2 original center: [0. 0. 0.]\n",
      "LOD 1 aligned center: [0. 0. 0.]\n",
      "LOD 2 aligned center: [ 5.64327503e-05 -1.44660879e-03 -6.56694029e-04]\n",
      "Processing LOD1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158513/898363163.py:211: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  Image.fromarray(color, mode=\"RGB\").save(save_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LOD2...\n",
      "LOD 1 original center: [0. 0. 0.]\n",
      "LOD 2 original center: [0. 0. 0.]\n",
      "LOD 1 aligned center: [0. 0. 0.]\n",
      "LOD 2 aligned center: [-1.08754812e-04  5.39442412e-03  6.41021555e-05]\n",
      "Processing LOD1...\n",
      "Processing LOD2...\n",
      "LOD 1 original center: [0. 0. 0.]\n",
      "LOD 2 original center: [0. 0. 0.]\n",
      "LOD 1 aligned center: [0. 0. 0.]\n",
      "LOD 2 aligned center: [ 2.04349397e-06  3.40405985e-05 -1.02356304e-04]\n",
      "Processing LOD1...\n",
      "Processing LOD2...\n",
      "LOD 1 original center: [0. 0. 0.]\n",
      "LOD 2 original center: [0. 0. 0.]\n",
      "LOD 1 aligned center: [0. 0. 0.]\n",
      "LOD 2 aligned center: [-0.00035736  0.01106077 -0.01301308]\n",
      "Processing LOD1...\n",
      "Processing LOD2...\n",
      "LOD 1 original center: [0. 0. 0.]\n",
      "LOD 2 original center: [0. 0. 0.]\n",
      "LOD 1 aligned center: [0. 0. 0.]\n",
      "LOD 2 aligned center: [-0.00294319  0.00043693  0.00021082]\n",
      "Processing LOD1...\n",
      "Processing LOD2...\n"
     ]
    }
   ],
   "source": [
    "# ─── Config ───────────────────────────────────────────────────────\n",
    "# scene_num = 46\n",
    "\n",
    "threshold_degrees = 5.0\n",
    "angle_thresh = np.deg2rad(threshold_degrees)\n",
    "# RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD_data_50\"\n",
    "RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD50_opaque_normalized_1radius_triangulated\"\n",
    "\n",
    "SCENES = range(46, 51)  # Assuming scenes are numbered from 1 to 50\n",
    "LODS = [1, 2]\n",
    "\n",
    "for scene_num in SCENES:\n",
    "    # ─── 1. Load LOD meshes into dict ─────────────────────────────────\n",
    "    lod_meshes = {}\n",
    "    for lod in LODS:\n",
    "        path = os.path.join(RAW_LOD_DATASET_ROOT, str(scene_num), f\"lod{lod}.obj\")\n",
    "        loaded = trimesh.load(path, process=False)\n",
    "        lod_mesh = (\n",
    "            trimesh.util.concatenate(loaded.geometry.values())\n",
    "            if isinstance(loaded, trimesh.Scene)\n",
    "            else loaded\n",
    "        )\n",
    "        lod_meshes[lod] = lod_mesh\n",
    "\n",
    "    # ─── 2. Align meshes ──────────────────────────────────────────────\n",
    "    aligned_meshes = align_lods_1_2_only(lod_meshes, center_before=True, samples=4000)\n",
    "    \n",
    "    # ─── 2.1 Sanitize transparency ────────────────────────────────────\n",
    "    # ─── 2.1 Sanitize transparency ────────────────────────────────────\n",
    "    # debug_face_colors(aligned_meshes)  # Debug first\n",
    "    # make_faces_opaque_preserve_texture(aligned_meshes)\n",
    "    # debug_face_colors(aligned_meshes)  # Check after fix\n",
    "\n",
    "    scene = trimesh.Scene()\n",
    "    # # ─── 3. Build scene dict with crease lines ────────────────────────\n",
    "    scene_dict = {}\n",
    "    \n",
    "    for lod, mesh in aligned_meshes.items():\n",
    "        print(f\"Processing LOD{lod}...\")\n",
    "\n",
    "        # Step 1: Weld mesh for edge adjacency analysis\n",
    "        welded = trimesh.Trimesh(vertices=mesh.vertices.copy(),\n",
    "                                faces=mesh.faces.copy(),\n",
    "                                process=True)\n",
    "        # Step 2: Detect creases\n",
    "        fa = welded.face_adjacency_angles\n",
    "        edges = welded.face_adjacency_edges\n",
    "        mask = fa > angle_thresh\n",
    "        \n",
    "        # Filter to manifold edges only\n",
    "        from collections import defaultdict\n",
    "        edge_count = defaultdict(int)\n",
    "        for face in welded.faces:\n",
    "            for i in range(3):\n",
    "                e = tuple(sorted((face[i], face[(i+1)%3])))\n",
    "                edge_count[e] += 1\n",
    "        filtered_edges = [e for e in edges[mask] if edge_count[tuple(sorted(e))] == 2]\n",
    "\n",
    "        # Step 3: Create pyrender line mesh for rendering\n",
    "        line_mesh = line_segments_to_cylinders(welded.vertices, filtered_edges)\n",
    "\n",
    "        # Step 4: Render together with the mesh\n",
    "        AZIMUTH_STEP = 45\n",
    "        ELEVATIONS = [0, 30]\n",
    "        OUTPUT_ROOT = \"/home/athiwat/progressive_img2sketch/resources/test_orbit\"  # customize this\n",
    "\n",
    "        render_orbit_with_creases(\n",
    "            mesh=mesh,\n",
    "            line_mesh=line_mesh,\n",
    "            lod_meshes=aligned_meshes,\n",
    "            scene_number=scene_num,\n",
    "            lod=lod,\n",
    "            output_root=OUTPUT_ROOT,\n",
    "            azimuths=range(0, 360, AZIMUTH_STEP),\n",
    "            elevations=ELEVATIONS\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athiwat_controlnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
