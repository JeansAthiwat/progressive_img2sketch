{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d573011b",
   "metadata": {},
   "source": [
    "# This notebook does the whole pipeline starting from the raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7ffdd",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\" # important to be set before importing pyrender\n",
    "\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "import matplotlib.pyplot as plt\n",
    "# from dataset_processing.fix_normal import traverse_and_fix\n",
    "\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from trimesh.visual import ColorVisuals\n",
    "from trimesh.scene.lighting import DirectionalLight, PointLight\n",
    "\n",
    "# sanity = trimesh.load(\"/home/athiwat/progressive_img2sketch/resources/LOD_for_icp/46/lod2.obj\", process=True)\n",
    "# # to mesh\n",
    "# if isinstance(sanity, trimesh.Scene):\n",
    "#     sanity = sanity.dump(concatenate=True)\n",
    "# trimesh.repair.fix_normals(sanity)\n",
    "# trimesh.repair.fix_inversion(sanity)\n",
    "# trimesh.repair.fix_winding(sanity)\n",
    "# trimesh.repair.broken_faces(sanity)\n",
    "# sanity.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f07353",
   "metadata": {},
   "source": [
    "### 1. Correcting the UV Paths for the LOD dataset\n",
    "\n",
    "just need to run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3270772",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_Y_AXIS = True  # Set to True to visualize the Y-axis\n",
    "RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD_for_icp\"\n",
    "\n",
    "# traverse_and_fix(RAW_LOD_DATASET_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf415ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_scene_by_bbox(scene: trimesh.Scene) -> trimesh.Scene:\n",
    "    \"\"\"\n",
    "    Center the scene at the origin based on its bounding-box center.\n",
    "    \"\"\"\n",
    "    min_corner, max_corner = scene.bounds\n",
    "    center = (min_corner + max_corner) / 2.0\n",
    "    scene.apply_translation(-center)\n",
    "    return scene\n",
    "\n",
    "def get_registration_matrix(\n",
    "    source_mesh: trimesh.Trimesh,\n",
    "    target_mesh: trimesh.Trimesh,\n",
    "    samples: int = 3000,\n",
    "    icp_first: int = 1,\n",
    "    icp_final: int = 30\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the ICP transformation matrix that aligns source_mesh to target_mesh.\n",
    "    \"\"\"\n",
    "    matrix, _ = trimesh.registration.mesh_other(\n",
    "        source_mesh,\n",
    "        target_mesh,\n",
    "        samples=samples,\n",
    "        scale=False,\n",
    "        icp_first=icp_first,\n",
    "        icp_final=icp_final\n",
    "    )\n",
    "    return matrix\n",
    "\n",
    "def align_lods(scenes: dict[int, trimesh.Scene], center_before: bool = False):\n",
    "    # — step 1: (optional) rough centering to help ICP converge —\n",
    "    if center_before:\n",
    "        for lod in scenes:\n",
    "            scenes[lod] = center_scene_by_bbox(scenes[lod])\n",
    "\n",
    "    # — step 2: extract single meshes for ICP —\n",
    "    \n",
    "    meshes = {\n",
    "        lod: trimesh.util.concatenate(list(scenes[lod].geometry.values()))\n",
    "        for lod in scenes\n",
    "    }\n",
    "\n",
    "    #show original bbox centers\n",
    "    for lod, mesh in meshes.items():\n",
    "        min_corner, max_corner = mesh.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} original center: {center}\")\n",
    "        \n",
    "    # ICP: 2→1 then 3→2\n",
    "    t2_1 = get_registration_matrix(meshes[2], meshes[1])\n",
    "    t3_2 = get_registration_matrix(meshes[3], meshes[2])\n",
    "\n",
    "    # apply those transforms\n",
    "    scenes[2].apply_transform(t2_1)\n",
    "    scenes[3].apply_transform(t2_1 @ t3_2)\n",
    "\n",
    "    # show aligned bbox centers\n",
    "    for lod, scene in scenes.items():\n",
    "        min_corner, max_corner = scene.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} aligned center: {center}\")\n",
    "    # — step 3: **final centering** based on aligned LOD1 bbox —\n",
    "    min1, max1 = scenes[1].bounds\n",
    "    center1 = (min1 + max1) * 0.5\n",
    "    for lod in scenes:\n",
    "        scenes[lod].apply_translation(-center1)\n",
    "\n",
    "    return scenes\n",
    "\n",
    "def look_at_matrix(eye: np.ndarray, target: np.ndarray, up: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a camera-to-world pose matrix for pyrender given eye, target, up vectors.\n",
    "    \"\"\"\n",
    "    f = (target - eye)\n",
    "    f /= np.linalg.norm(f)\n",
    "    # avoid parallel up/f\n",
    "    if np.isclose(np.linalg.norm(np.cross(f, up)), 0):\n",
    "        up = np.array([0, 0, 1]) if np.isclose(abs(f.dot([0, 1, 0])), 1) else np.array([0, 1, 0])\n",
    "    s = np.cross(f, up); s /= np.linalg.norm(s)\n",
    "    u = np.cross(s, f); u /= np.linalg.norm(u)\n",
    "\n",
    "    # view matrix (world→camera)\n",
    "    view = np.array([\n",
    "        [ s[0],  s[1],  s[2], -s.dot(eye)],\n",
    "        [ u[0],  u[1],  u[2], -u.dot(eye)],\n",
    "        [-f[0], -f[1], -f[2],  f.dot(eye)],\n",
    "        [    0,     0,     0,           1]\n",
    "    ])\n",
    "    # invert → camera pose (camera→world)\n",
    "    return np.linalg.inv(view)\n",
    "\n",
    "def align_lods_1_2_only(meshes: dict[int, trimesh.base.Trimesh], center_before: bool = False, samples: int = 3000):\n",
    "    # Show original bbox centers\n",
    "    for lod, mesh in [(1, meshes[1]), (2, meshes[2])]:\n",
    "        min_corner, max_corner = mesh.bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} original center: {center}\")\n",
    "        \n",
    "    # — step 1: (optional) rough centering to help ICP converge —\n",
    "    if center_before:\n",
    "        for lod in [1, 2]:\n",
    "            meshes[lod] = center_scene_by_bbox(meshes[lod])\n",
    "\n",
    "    # — step 2: extract meshes —\n",
    "\n",
    "    mesh1 = meshes[1]\n",
    "    mesh2 = meshes[2]\n",
    "    # ICP: 2 → 1\n",
    "    t2_1 = get_registration_matrix(mesh2, mesh1, samples=samples)\n",
    "    meshes[2].apply_transform(t2_1)\n",
    "\n",
    "    # Show aligned bbox centers\n",
    "    for lod in [1, 2]:\n",
    "        min_corner, max_corner = meshes[lod].bounds\n",
    "        center = (min_corner + max_corner) / 2.0\n",
    "        print(f\"LOD {lod} aligned center: {center}\")\n",
    "\n",
    "    # — step 3: center both based on aligned LOD1 —\n",
    "    min1, max1 = meshes[1].bounds\n",
    "    center1 = (min1 + max1) * 0.5\n",
    "    for lod in [1, 2]:\n",
    "        meshes[lod].apply_translation(-center1)\n",
    "\n",
    "    return meshes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fcb28",
   "metadata": {},
   "source": [
    "### 2. Load the scene and orbit capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ─── Config ───────────────────────────────────────────────────────\n",
    "scene_num = 46\n",
    "LODS = [1, 2]\n",
    "threshold_degrees = 5.0\n",
    "angle_thresh = np.deg2rad(threshold_degrees)\n",
    "# RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD_data_50\"\n",
    "RAW_LOD_DATASET_ROOT = \"/home/athiwat/progressive_img2sketch/resources/LOD_for_icp\"\n",
    "\n",
    "# ─── 1. Load LOD meshes into dict ─────────────────────────────────\n",
    "lod_meshes = {}\n",
    "for lod in LODS:\n",
    "    path = os.path.join(RAW_LOD_DATASET_ROOT, str(scene_num), f\"lod{lod}.obj\")\n",
    "    loaded = trimesh.load(path, process=False)\n",
    "    mesh = (\n",
    "        trimesh.util.concatenate(loaded.geometry.values())\n",
    "        if isinstance(loaded, trimesh.Scene)\n",
    "        else loaded\n",
    "    )\n",
    "    lod_meshes[lod] = mesh\n",
    "\n",
    "print(f\"check type of lod_meshes[1]: {type(lod_meshes[1])}\")\n",
    "print(f\"check type of lod_meshes[2]: {type(lod_meshes[2])}\")\n",
    "# ─── 2. Align meshes ──────────────────────────────────────────────\n",
    "aligned_meshes = align_lods_1_2_only(lod_meshes, center_before=True, samples=4000)\n",
    "# aligned_meshes = lod_meshes.copy()\n",
    "scene = trimesh.Scene()\n",
    "# for lod, mesh in aligned_meshes.items():\n",
    "#     scene.add_geometry(mesh, geom_name=f\"LOD{lod}\")\n",
    "# scene.add_geometry(aligned_meshes[2], geom_name=\"LOD1\")\n",
    "\n",
    "# scene.show()\n",
    "# # ─── 3. Build scene dict with crease lines ────────────────────────\n",
    "scene_dict = {}\n",
    "import pyrender\n",
    "from pyrender import Primitive, Mesh as PyMesh, PerspectiveCamera, SpotLight, OffscreenRenderer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_line_primitive(vertices, edges):\n",
    "    \"\"\"\n",
    "    Create a pyrender.Mesh primitive from line segments.\n",
    "    \"\"\"\n",
    "    if len(edges) == 0:\n",
    "        return None\n",
    "\n",
    "    segments = vertices[np.array(edges)]  # shape (N, 2, 3)\n",
    "    pos = segments.reshape(-1, 3)         # flatten (N*2, 3)\n",
    "    idx = np.arange(len(pos)).reshape(-1, 2)\n",
    "\n",
    "    color = np.tile([0.0, 0.0, 0.0, 1.0], (pos.shape[0], 1))  # RGBA\n",
    "    prim = Primitive(positions=pos, indices=idx, mode=1, color_0=color)\n",
    "    return PyMesh(primitives=[prim])\n",
    "\n",
    "def render_with_creases(mesh, line_mesh, width=800, height=600):\n",
    "    \"\"\"\n",
    "    Render both a textured mesh and a line primitive.\n",
    "    \"\"\"\n",
    "    scene = pyrender.Scene()\n",
    "\n",
    "    # 1. Mesh (smooth shaded)\n",
    "    mesh_tex = PyMesh.from_trimesh(mesh, smooth=True)\n",
    "    scene.add(mesh_tex)\n",
    "\n",
    "    # 2. Lines\n",
    "    if line_mesh is not None:\n",
    "        scene.add(line_mesh)\n",
    "\n",
    "    # 3. Camera\n",
    "    camera = PerspectiveCamera(yfov=np.pi/3.0, aspectRatio=width/height)\n",
    "    cam_pose = np.array([\n",
    "        [0.0, -np.sqrt(2)/2,  np.sqrt(2)/2, 0.3],\n",
    "        [1.0,  0.0,           0.0,          0.0],\n",
    "        [0.0,  np.sqrt(2)/2,  np.sqrt(2)/2, 0.35],\n",
    "        [0.0,  0.0,           0.0,          1.0],\n",
    "    ])\n",
    "    scene.add(camera, pose=cam_pose)\n",
    "\n",
    "    # 4. Lighting\n",
    "    light = SpotLight(color=np.ones(3), intensity=3.0,\n",
    "                      innerConeAngle=np.pi/16.0,\n",
    "                      outerConeAngle=np.pi/6.0)\n",
    "    scene.add(light, pose=cam_pose)\n",
    "\n",
    "    # 5. Render\n",
    "    r = OffscreenRenderer(viewport_width=width, viewport_height=height)\n",
    "    color, depth = r.render(scene)\n",
    "    r.delete()\n",
    "\n",
    "    return color, depth\n",
    "\n",
    "\n",
    "# ─── Main Processing Loop ───────────────────────────────────────\n",
    "for lod, mesh in aligned_meshes.items():\n",
    "    print(f\"Processing LOD{lod}...\")\n",
    "\n",
    "    # Step 1: Weld mesh for edge adjacency analysis\n",
    "    welded = trimesh.Trimesh(vertices=mesh.vertices.copy(),\n",
    "                             faces=mesh.faces.copy(),\n",
    "                             process=True)\n",
    "\n",
    "    # Step 2: Detect creases\n",
    "    fa = welded.face_adjacency_angles\n",
    "    edges = welded.face_adjacency_edges\n",
    "    mask = fa > angle_thresh\n",
    "\n",
    "    # Filter to manifold edges only\n",
    "    from collections import defaultdict\n",
    "    edge_count = defaultdict(int)\n",
    "    for face in welded.faces:\n",
    "        for i in range(3):\n",
    "            e = tuple(sorted((face[i], face[(i+1)%3])))\n",
    "            edge_count[e] += 1\n",
    "    filtered_edges = [e for e in edges[mask] if edge_count[tuple(sorted(e))] == 2]\n",
    "\n",
    "    # Step 3: Create pyrender line primitive\n",
    "    line_mesh = create_line_primitive(welded.vertices, filtered_edges)\n",
    "\n",
    "    # Step 4: Render together with the mesh\n",
    "    color, depth = render_with_creases(mesh, line_mesh)\n",
    "\n",
    "    # Step 5: Show output\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(color)\n",
    "    plt.title(f\"LOD{lod} Color\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(depth, cmap=\"gray_r\")\n",
    "    plt.title(\"Depth\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athiwat_controlnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
